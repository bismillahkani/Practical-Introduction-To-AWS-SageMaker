{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-classification-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOil1Ulwzn05Y8+b37hS6pw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a288f4a12d84b49ada42d4ed92b8c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a0ce0700a7f43308b5f7ee19ad1c134",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_607c52b3f11b49b88d6b4db2e9884385",
              "IPY_MODEL_1cd175fb39d74612b204f784daf1ff48"
            ]
          }
        },
        "1a0ce0700a7f43308b5f7ee19ad1c134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "607c52b3f11b49b88d6b4db2e9884385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60afcd2e564042b69ae144980f50f008",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c8e012b37ba4e46971d7fdea604a2e1"
          }
        },
        "1cd175fb39d74612b204f784daf1ff48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99595974a5364d9da260616811e3e0d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 135110656/? [00:04&lt;00:00, 30489002.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9761a446cf5b41dc80e6db7602c494e2"
          }
        },
        "60afcd2e564042b69ae144980f50f008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c8e012b37ba4e46971d7fdea604a2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99595974a5364d9da260616811e3e0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9761a446cf5b41dc80e6db7602c494e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bismillahkani/Practical-Introduction-To-AWS-SageMaker/blob/master/cifar10_classification_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9IzIFcgL69V",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR10 image classification using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxVzZsf5NNfH",
        "colab_type": "text"
      },
      "source": [
        "Based on https://jovian.ml/aakashns/05-cifar10-cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ojjoh60KNGF",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDelWZFF9Qna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SageMaker has issues with torch version 1.6.0. Uncomment the below lines and restart runtime to use lower version. \n",
        "# !pip install torch==1.4.0 -q\n",
        "# !pip install torchvision==0.6.0 -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDVF_tb8Jkh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqMaGVnG0GS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "436581d8-7c32-4bf5-e607-76ed0c632224"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmIJ3UTxKSPV",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5UJRHlPJsEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0a288f4a12d84b49ada42d4ed92b8c90",
            "1a0ce0700a7f43308b5f7ee19ad1c134",
            "607c52b3f11b49b88d6b4db2e9884385",
            "1cd175fb39d74612b204f784daf1ff48",
            "60afcd2e564042b69ae144980f50f008",
            "8c8e012b37ba4e46971d7fdea604a2e1",
            "99595974a5364d9da260616811e3e0d3",
            "9761a446cf5b41dc80e6db7602c494e2"
          ]
        },
        "outputId": "ec59fd17-01cf-4c5b-b66d-969297e64279"
      },
      "source": [
        "# Dowload the dataset\n",
        "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url, '.')\n",
        "\n",
        "# Extract from archive\n",
        "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
        "    tar.extractall(path='./data')\n",
        "\n",
        "data_dir = './data/cifar10'\n",
        "\n",
        "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "# Split into train and validation dataset\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "batch_size=128\n",
        "\n",
        "# Training and validation dataloaders\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz to ./cifar10.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a288f4a12d84b49ada42d4ed92b8c90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kIDNDPdKVM9",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqT2Mu4UJ01L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "  \"\"\"Model evaluation metrics\"\"\"\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "  \"\"\"Base Image classification class\"\"\" \n",
        "  def training_step(self, batch):\n",
        "      images, labels = batch \n",
        "      out = self(images)                  # Generate predictions\n",
        "      loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "      return loss\n",
        "  \n",
        "  def validation_step(self, batch):\n",
        "      images, labels = batch \n",
        "      out = self(images)                    # Generate predictions\n",
        "      loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "      acc = accuracy(out, labels)           # Calculate accuracy\n",
        "      return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "      \n",
        "  def validation_epoch_end(self, outputs):\n",
        "      batch_losses = [x['val_loss'] for x in outputs]\n",
        "      epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "      batch_accs = [x['val_acc'] for x in outputs]\n",
        "      epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "      return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "  \n",
        "  def epoch_end(self, epoch, result):\n",
        "      print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "          epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "\n",
        "class Cifar10CnnModel(ImageClassificationBase):\n",
        "  \"\"\"cifar10 classfification model\"\"\"\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.network = nn.Sequential(\n",
        "          nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
        "\n",
        "          nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
        "\n",
        "          nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "\n",
        "          nn.Flatten(), \n",
        "          nn.Linear(256*4*4, 1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(1024, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(512, 10))\n",
        "      \n",
        "  def forward(self, xb):\n",
        "      return self.network(xb)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7rqiruHJ3lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Cifar10CnnModel()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Jn2lyvKZF5",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoOzFo2SJ834",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiVwpB_yJ-9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_default_device()\n",
        "\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHD1-RWBKcnq",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqqB-hOBjmwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "  \"\"\" Training script \"\"\"\n",
        "  history = []\n",
        "  optimizer = opt_func(model.parameters(), lr)\n",
        "  for epoch in range(epochs):\n",
        "      # Training Phase \n",
        "      model.train()\n",
        "      train_losses = []\n",
        "      for batch in train_loader:\n",
        "          loss = model.training_step(batch)\n",
        "          train_losses.append(loss)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "      # Validation phase\n",
        "      result = evaluate(model, val_loader)\n",
        "      result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "      model.epoch_end(epoch, result)\n",
        "      history.append(result)\n",
        "  return history"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Kw2BDvKDDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a4a4a9d8-8f92-4c90-c0c7-3e56d40cf381"
      },
      "source": [
        "model = to_device(Cifar10CnnModel(), device)\n",
        "\n",
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 1.7836, val_loss: 1.4507, val_acc: 0.4604\n",
            "Epoch [1], train_loss: 1.2696, val_loss: 1.1453, val_acc: 0.5862\n",
            "Epoch [2], train_loss: 1.0294, val_loss: 0.9585, val_acc: 0.6574\n",
            "Epoch [3], train_loss: 0.8673, val_loss: 0.8742, val_acc: 0.6896\n",
            "Epoch [4], train_loss: 0.7353, val_loss: 0.8016, val_acc: 0.7206\n",
            "Epoch [5], train_loss: 0.6355, val_loss: 0.7874, val_acc: 0.7294\n",
            "Epoch [6], train_loss: 0.5456, val_loss: 0.7279, val_acc: 0.7485\n",
            "Epoch [7], train_loss: 0.4682, val_loss: 0.7290, val_acc: 0.7614\n",
            "Epoch [8], train_loss: 0.3885, val_loss: 0.7537, val_acc: 0.7630\n",
            "Epoch [9], train_loss: 0.3238, val_loss: 0.7953, val_acc: 0.7669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87X5kqoLKgVO",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aprsaYzqnunk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model artifacts as .pth file\n",
        "torch.save(model.state_dict(),'model.pth')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thYAK7erKiu9",
        "colab_type": "text"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ItTucBgoGxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce0fe94-222d-4ab3-a259-f6e92648bd32"
      },
      "source": [
        "# create cifar10 model and load the model weights\n",
        "model_cifar = to_device(Cifar10CnnModel(), device)\n",
        "model_cifar.load_state_dict(torch.load('model.pth'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0OAxYfMOTIH",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j9sK6E3qx-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test dataset\n",
        "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOrUNTkmxx-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_image(img, model):\n",
        "  \"\"\"predict function to predict the image class\"\"\"\n",
        "  # Convert to a batch of 1\n",
        "  xb = to_device(img.unsqueeze(0), device)\n",
        "  # Get predictions from model\n",
        "  yb = model(xb)\n",
        "  # Pick index with highest probability\n",
        "  _, preds  = torch.max(yb, dim=1)\n",
        "  # Retrieve the class label\n",
        "  return dataset.classes[preds[0].item()]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftnc1b9Fx1Li",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f3dca29a-292f-433b-9471-b85f1a4fcd8b"
      },
      "source": [
        "img, label = test_dataset[0]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model_cifar))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: airplane , Predicted: ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th8BW0_hNeX5",
        "colab_type": "text"
      },
      "source": [
        "### Prepare for deployment in AWS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fmot8o0Nhxo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* After the model is trained, save the model artifcats as 'model.pth'\n",
        "* Test the model by loading the model artifacts and doing inference\n",
        "* Once testing is ok, download the 'model.pth' file. "
      ]
    }
  ]
}